{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsimeon/AI-For-Beginners/blob/main/LC1_2_Build_a_Simple_RAG_and_then_a_Conversational_RAG_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3eREw2pcdqm"
      },
      "source": [
        "# Basic RAG System with LangChain\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QA Search Engine using Large Language Models - ChatGPT\n",
        "\n",
        "Here we use an Open AI LLM to generate contextual embeddings for each wikipedia article.\n",
        "\n",
        "Then we use ChatGPT (GPT3.5) to answer questions just as a human would by searching for the most similar articles based on our input queries.\n",
        "\n",
        "The new model, `text-embedding-3-small` is our new highly efficient embedding model and provides a significant upgrade over its predecessor, the `text-embedding-ada-002` model released in December 2022.\n",
        "\n",
        "GPT-3.5 models can understand and generate natural language or code. The most capable and cost effective model in the GPT-3.5 family is `gpt-3.5-turbo` which has been optimized for chat using the Chat Completions API but works well for traditional completions tasks as well."
      ],
      "metadata": {
        "id": "is--iN7fcdqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QA Search Engine using Large Language Models - ChatGPT\n",
        "\n",
        "Here we use an Open AI LLM to generate contextual embeddings for each wikipedia article.\n",
        "\n",
        "Then we use ChatGPT (GPT3.5) to answer questions just as a human would by searching for the most similar article based on our input queries.\n",
        "\n",
        "The new model, `text-embedding-3-small` is our new highly efficient embedding model and provides a significant upgrade over its predecessor, the `text-embedding-ada-002` model released in December 2022.\n",
        "\n",
        "Stronger performance. Comparing `text-embedding-ada-002` to `text-embedding-3-small`, the average score on a commonly used benchmark for multi-language retrieval (MIRACL(opens in a new window)) has increased from 31.4% to 44.0%, while the average score on a commonly used benchmark for English tasks (MTEB(opens in a new window)) has increased from 61.0% to 62.3%.\n",
        "\n",
        "Reduced price. `text-embedding-3-small` is also substantially more efficient than our previous generation `text-embedding-ada-002` model. Pricing for `text-embedding-3-small` has therefore been reduced by 5X compared to `text-embedding-ada-002`, from a price per 1k tokens of $0.0001 to $0.00002.\n",
        "\n",
        "GPT-3.5 models can understand and generate natural language or code. The most capable and cost effective model in the GPT-3.5 family is `gpt-3.5-turbo` which has been optimized for chat using the Chat Completions API but works well for traditional completions tasks as well."
      ],
      "metadata": {
        "id": "eiC3bewyVzQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dependencies"
      ],
      "metadata": {
        "id": "FPj5mhnc4lp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.1.16\n",
        "!pip install langchain-openai==0.1.3\n",
        "!pip install langchain-community==0.0.33"
      ],
      "metadata": {
        "id": "3J_Z9mKEa8fM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08dcc55-17e3-4fe0-b444-e510ad5d18dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.1.16\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.16)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.16)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain==0.1.16)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.42 (from langchain==0.1.16)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.16)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.16)\n",
            "  Downloading langsmith-0.1.77-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.16)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain==0.1.16)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16)\n",
            "  Downloading orjson-3.10.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.16) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "Successfully installed dataclasses-json-0.6.7 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.1.16 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.2 langsmith-0.1.77 marshmallow-3.21.3 mypy-extensions-1.0.0 orjson-3.10.4 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting langchain-openai==0.1.3\n",
            "  Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.3) (0.1.52)\n",
            "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai==0.1.3)\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.5.2 (from langchain-openai==0.1.3)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (0.1.77)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (2.7.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.3)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (3.10.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai==0.1.3) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.3) (2.0.7)\n",
            "Installing collected packages: h11, tiktoken, httpcore, httpx, openai, langchain-openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain-openai-0.1.3 openai-1.34.0 tiktoken-0.7.0\n",
            "Collecting langchain-community==0.0.33\n",
            "  Downloading langchain_community-0.0.33-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (0.6.7)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.43 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (0.1.52)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (0.1.77)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.33) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.33) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.33) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.33) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (2.7.3)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.33) (3.10.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.33) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.33) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.33) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.33) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.33) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.33) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.43->langchain-community==0.0.33) (2.18.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.33) (1.0.0)\n",
            "Installing collected packages: langchain-community\n",
            "  Attempting uninstall: langchain-community\n",
            "    Found existing installation: langchain-community 0.0.38\n",
            "    Uninstalling langchain-community-0.0.38:\n",
            "      Successfully uninstalled langchain-community-0.0.38\n",
            "Successfully installed langchain-community-0.0.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-chroma==0.1.0\n",
        "!pip install langchainhub==0.1.15"
      ],
      "metadata": {
        "id": "W9SJBRTmdiF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4c5d58-624c-4fc1-af13-7fe490da773f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-chroma==0.1.0\n",
            "  Downloading langchain_chroma-0.1.0-py3-none-any.whl (8.5 kB)\n",
            "Collecting chromadb<0.5.0,>=0.4.0 (from langchain-chroma==0.1.0)\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<1,>=0.95.2 (from langchain-chroma==0.1.0)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.2.0,>=0.1.40 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma==0.1.0) (0.1.52)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma==0.1.0) (1.25.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.7.3)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (4.12.2)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.12.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (8.3.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.10.4)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi<1,>=0.95.2->langchain-chroma==0.1.0)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi<1,>=0.95.2->langchain-chroma==0.1.0)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma==0.1.0) (0.27.0)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma==0.1.0) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi<1,>=0.95.2->langchain-chroma==0.1.0)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi<1,>=0.95.2->langchain-chroma==0.1.0)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi<1,>=0.95.2->langchain-chroma==0.1.0)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain-chroma==0.1.0) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain-chroma==0.1.0) (0.1.77)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain-chroma==0.1.0) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.0.1)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma==0.1.0)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma==0.1.0) (3.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma==0.1.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma==0.1.0) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma==0.1.0) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma==0.1.0) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi<1,>=0.95.2->langchain-chroma==0.1.0) (2.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.40->langchain-chroma==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.12.1)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (7.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.63.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.3.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.23.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (13.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma==0.1.0) (1.2.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.19.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (2.16.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma==0.1.0) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=c85d2f9490af0db6dbc0751fc00cedea3e6f89be56a05db8a4ad3ee492f0892a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, uvicorn, ujson, python-multipart, python-dotenv, pulsar-client, overrides, opentelemetry-util-http, opentelemetry-proto, humanfriendly, httptools, dnspython, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, email_validator, coloredlogs, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, fastapi, chromadb, langchain-chroma\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 deprecated-1.2.14 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 httptools-0.6.1 humanfriendly-10.0 kubernetes-30.1.0 langchain-chroma-0.1.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.18.0 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 overrides-7.7.0 posthog-3.5.0 pulsar-client-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 python-multipart-0.0.9 starlette-0.37.2 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n",
            "Collecting langchainhub==0.1.15\n",
            "  Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchainhub==0.1.15) (2.31.0)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub==0.1.15)\n",
            "  Downloading types_requests-2.32.0.20240602-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub==0.1.15) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub==0.1.15) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub==0.1.15) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub==0.1.15) (2024.6.2)\n",
            "Installing collected packages: types-requests, langchainhub\n",
            "Successfully installed langchainhub-0.1.15 types-requests-2.32.0.20240602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter API Tokens"
      ],
      "metadata": {
        "id": "PtBa7rlWJWH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass()"
      ],
      "metadata": {
        "id": "Av1UpSgXZUsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2ba1275-4497-43ee-9ced-d22d44a93385"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if using Azure Open AI you might need to configure it based on how it is setup in your org.\n",
        "\n",
        "Refer to [this](https://python.langchain.com/docs/integrations/llms/azure_openai/) for more details"
      ],
      "metadata": {
        "id": "T5rOqCyianbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
      ],
      "metadata": {
        "id": "1PIStD04Zp9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Wikipedia Data"
      ],
      "metadata": {
        "id": "wmUCqWtf5gpk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQjM-gKUDT1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835bb9b2-4521-42f8-f2f5-a3a7f963927e"
      },
      "source": [
        "import gzip\n",
        "import json\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Download a file from a URL\n",
        "def http_get(url, path) -> None:\n",
        "    \"\"\"\n",
        "    Downloads a URL to a given path on disc\n",
        "    \"\"\"\n",
        "    if os.path.dirname(path) != \"\":\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "\n",
        "    req = requests.get(url, stream=True)\n",
        "    if req.status_code != 200:\n",
        "        print(\"Exception when trying to download {}. Response {}\".format(url, req.status_code), file=sys.stderr)\n",
        "        req.raise_for_status()\n",
        "        return\n",
        "\n",
        "    download_filepath = path + \"_part\"\n",
        "    with open(download_filepath, \"wb\") as file_binary:\n",
        "        content_length = req.headers.get(\"Content-Length\")\n",
        "        total = int(content_length) if content_length is not None else None\n",
        "        progress = tqdm(unit=\"B\", total=total, unit_scale=True)\n",
        "        for chunk in req.iter_content(chunk_size=1024):\n",
        "            if chunk:  # filter out keep-alive new chunks\n",
        "                progress.update(len(chunk))\n",
        "                file_binary.write(chunk)\n",
        "\n",
        "    os.rename(download_filepath, path)\n",
        "    progress.close()\n",
        "\n",
        "\n",
        "wikipedia_filepath = 'simplewiki-2020-11-01.jsonl.gz'\n",
        "\n",
        "http_get('http://sbert.net/datasets/simplewiki-2020-11-01.jsonl.gz', wikipedia_filepath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50.2M/50.2M [00:03<00:00, 16.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import json\n",
        "\n",
        "wikipedia_filepath = 'simplewiki-2020-11-01.jsonl.gz'\n",
        "\n",
        "passages = []\n",
        "with gzip.open(wikipedia_filepath, 'rt', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        data = json.loads(line.strip())\n",
        "\n",
        "        #Add all paragraphs\n",
        "        #passages.extend(data['paragraphs'])\n",
        "\n",
        "        #Only add the first paragraph\n",
        "        passages.append(data['paragraphs'][0])\n",
        "\n",
        "print(\"Passages:\", len(passages))"
      ],
      "metadata": {
        "id": "9_NrBVzteHaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad117874-f27d-4cd7-f091-55be4733aae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passages: 169597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We subset our data so we only use a subset of wikipedia to run things faster\n",
        "passages = [passage for passage in passages for x in ['fish', 'india', 'cheetah']\n",
        "              if x in passage.lower().split()]\n",
        "passages = [passage for passage in passages for x in ['flying fish', 'india', 'cheetah']\n",
        "              if x in passage.lower()]"
      ],
      "metadata": {
        "id": "Id4P7kZ-DT1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(passages)"
      ],
      "metadata": {
        "id": "e13_oFtlDT1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c89c7182-155c-4691-eaa3-2bc7d35cfaab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "793"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "passages[0]"
      ],
      "metadata": {
        "id": "sm77itlPEDx0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "56e9e804-94df-49f7-dd0a-932ef36d8a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Basil (\"Ocimum basilicum\") ( or ) is a plant of the Family Lamiaceae. It is also known as Sweet Basil or Tulsi. It is a tender low-growing herb that is grown as a perennial in warm, tropical climates. Basil is originally native to India and other tropical regions of Asia. It has been cultivated there for more than 5,000 years. It is prominently featured in many cuisines throughout the world. Some of them are Italian, Thai, Vietnamese and Laotian cuisines. It grows to between 30–60\\xa0cm tall. It has light green, silky leaves 3–5\\xa0cm long and 1–3\\xa0cm broad. The leaves are opposite each other. The flowers are quite big. They are white in color and arranged as a spike.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Open AI LLMs"
      ],
      "metadata": {
        "id": "KZUxQwCl5jY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "metadata": {
        "id": "0NKUgjxLL-Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate LLM Embeddings and store them in Chroma Vector DB\n",
        "\n",
        "**Chroma Vector DB** is a versatile, open-source vector database designed for managing and querying vector embeddings. It is easy to set up and integrates well with various AI tools and algorithms. Chroma is particularly useful for applications that require rapid and precise retrieval of content represented as embeddings—efficient data formats for text, images, and soon, audio and video.\n",
        "\n",
        "**Key Features:**\n",
        "- **Integration with AI Tools:** Chroma supports embedding functions from leading providers like OpenAI, Google, and Hugging Face, allowing for flexible and powerful data handling.\n",
        "- **Ease of Use:** The database provides default embedding functions, or users can integrate external APIs to generate embeddings.\n",
        "- **Efficient Querying:** Users can create collections to store embeddings, documents, and metadata. These can be queried to retrieve the most similar items, making information retrieval quick and effective.\n",
        "- **Flexible API:** Chroma offers a straightforward API that supports both standard operations and custom embedding functions.\n",
        "\n",
        "For more detailed information, visit the official Chroma documentation [here](https://docs.trychroma.com).\n"
      ],
      "metadata": {
        "id": "K1nD_kYA5ncq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passages[:3]"
      ],
      "metadata": {
        "id": "bbEe-0csNRmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cee5831-3959-40f3-b93e-656c64e45945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Basil (\"Ocimum basilicum\") ( or ) is a plant of the Family Lamiaceae. It is also known as Sweet Basil or Tulsi. It is a tender low-growing herb that is grown as a perennial in warm, tropical climates. Basil is originally native to India and other tropical regions of Asia. It has been cultivated there for more than 5,000 years. It is prominently featured in many cuisines throughout the world. Some of them are Italian, Thai, Vietnamese and Laotian cuisines. It grows to between 30–60\\xa0cm tall. It has light green, silky leaves 3–5\\xa0cm long and 1–3\\xa0cm broad. The leaves are opposite each other. The flowers are quite big. They are white in color and arranged as a spike.',\n",
              " 'The Roerich Pact is a treaty on Protection of Artistic and Scientific Institutions and Historic Monuments, signed by the representatives of 21 states in the Oval Office of the White House on 15 April 1935. As of January 1, 1990, the Roerich Pact had been ratified by ten nations: Brazil, Chile, Colombia, Cuba, the Dominican Republic, El Salvador, Guatemala, Mexico, the United States, and Venezuela. It went into effect on 26 August 1935. The Government of India approved the Treaty in 1948, but did not take any further formal action. The Roerich Pact is also known as \"Pax Cultura\" (\"Cultural Peace\" or \"Peace through Culture\"). The most important part of the Roerich Pact is the legal recognition that the protection of culture is always more important than any military necessity.',\n",
              " \"The Indian Air Force is the air arm of the Indian Military. The Royal Indian Air Force was founded on 1 April 1932 as part of the armed forces of the British Empire. In 1950, after independence, India dropped the word 'Royal' from the name.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
        "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
      ],
      "metadata": {
        "id": "HyFSs6xZfzok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The vectorstore we'll be using\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "# The embedding engine that will convert our text to vectors\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "KPRVzeE6NwE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "\n",
        "docs = [Document(page_content=doc) for doc in passages]"
      ],
      "metadata": {
        "id": "Xt-9DpXxXscN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[:3]"
      ],
      "metadata": {
        "id": "N3jwYefVL78q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3c47b5-8bc2-4454-884f-eebc55763ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Basil (\"Ocimum basilicum\") ( or ) is a plant of the Family Lamiaceae. It is also known as Sweet Basil or Tulsi. It is a tender low-growing herb that is grown as a perennial in warm, tropical climates. Basil is originally native to India and other tropical regions of Asia. It has been cultivated there for more than 5,000 years. It is prominently featured in many cuisines throughout the world. Some of them are Italian, Thai, Vietnamese and Laotian cuisines. It grows to between 30–60\\xa0cm tall. It has light green, silky leaves 3–5\\xa0cm long and 1–3\\xa0cm broad. The leaves are opposite each other. The flowers are quite big. They are white in color and arranged as a spike.'),\n",
              " Document(page_content='The Roerich Pact is a treaty on Protection of Artistic and Scientific Institutions and Historic Monuments, signed by the representatives of 21 states in the Oval Office of the White House on 15 April 1935. As of January 1, 1990, the Roerich Pact had been ratified by ten nations: Brazil, Chile, Colombia, Cuba, the Dominican Republic, El Salvador, Guatemala, Mexico, the United States, and Venezuela. It went into effect on 26 August 1935. The Government of India approved the Treaty in 1948, but did not take any further formal action. The Roerich Pact is also known as \"Pax Cultura\" (\"Cultural Peace\" or \"Peace through Culture\"). The most important part of the Roerich Pact is the legal recognition that the protection of culture is always more important than any military necessity.'),\n",
              " Document(page_content=\"The Indian Air Force is the air arm of the Indian Military. The Royal Indian Air Force was founded on 1 April 1932 as part of the armed forces of the British Empire. In 1950, after independence, India dropped the word 'Royal' from the name.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300)\n",
        "chunked_docs = splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "P_9jsBAJWMk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_docs[:3]"
      ],
      "metadata": {
        "id": "5Tu4rqnWYLFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bea85c5-fc69-4062-cedf-299dd0696e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Basil (\"Ocimum basilicum\") ( or ) is a plant of the Family Lamiaceae. It is also known as Sweet Basil or Tulsi. It is a tender low-growing herb that is grown as a perennial in warm, tropical climates. Basil is originally native to India and other tropical regions of Asia. It has been cultivated there for more than 5,000 years. It is prominently featured in many cuisines throughout the world. Some of them are Italian, Thai, Vietnamese and Laotian cuisines. It grows to between 30–60\\xa0cm tall. It has light green, silky leaves 3–5\\xa0cm long and 1–3\\xa0cm broad. The leaves are opposite each other. The flowers are quite big. They are white in color and arranged as a spike.'),\n",
              " Document(page_content='The Roerich Pact is a treaty on Protection of Artistic and Scientific Institutions and Historic Monuments, signed by the representatives of 21 states in the Oval Office of the White House on 15 April 1935. As of January 1, 1990, the Roerich Pact had been ratified by ten nations: Brazil, Chile, Colombia, Cuba, the Dominican Republic, El Salvador, Guatemala, Mexico, the United States, and Venezuela. It went into effect on 26 August 1935. The Government of India approved the Treaty in 1948, but did not take any further formal action. The Roerich Pact is also known as \"Pax Cultura\" (\"Cultural Peace\" or \"Peace through Culture\"). The most important part of the Roerich Pact is the legal recognition that the protection of culture is always more important than any military necessity.'),\n",
              " Document(page_content=\"The Indian Air Force is the air arm of the Indian Military. The Royal Indian Air Force was founded on 1 April 1932 as part of the armed forces of the British Empire. In 1950, after independence, India dropped the word 'Royal' from the name.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Vector DB and Retriever\n",
        "\n",
        "If you have already created `wiki_db`in the previous hands-on session then just load the DB and DO NOT run the following code to create the database again, ignore this when running on Colab"
      ],
      "metadata": {
        "id": "6RXepcnd1E7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create vector DB of docs and embeddings - takes 1 min on Colab\n",
        "chroma_db = Chroma.from_documents(documents=chunked_docs, collection_name='wiki_db',\n",
        "                                  embedding=openai_embed_model,\n",
        "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
        "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
        "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
        "                                  persist_directory=\"./wiki_db\")"
      ],
      "metadata": {
        "id": "_st2XDc3N2Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Vector DB from disk\n",
        "\n",
        "Run the following code if your vector DB already exists on disk from the previous hands-on session"
      ],
      "metadata": {
        "id": "9ju_zBIj1Zsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load from disk\n",
        "chroma_db = Chroma(persist_directory=\"./wiki_db\",\n",
        "                   collection_name='wiki_db',\n",
        "                   embedding_function=openai_embed_model)"
      ],
      "metadata": {
        "id": "pNvj0dDH1WDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chroma_db"
      ],
      "metadata": {
        "id": "NFC3uPqYop0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cfdfefd-8f6a-4744-ed03-bb1b10edd55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7a81797a71c0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_retriever = chroma_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
        "                                              search_kwargs={\"k\": 5, \"score_threshold\": 0.2})"
      ],
      "metadata": {
        "id": "pTmvHpCRlXOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_retriever.invoke('what is the capital of India?')"
      ],
      "metadata": {
        "id": "FXzDAhu9YHY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2827c01-2ecf-4d95-9c0d-4ab1b5bf2db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'),\n",
              " Document(page_content='The Republic of India is divided into twenty-eight States,and eight union territories including the National Capital Territory.'),\n",
              " Document(page_content=\"Kolkata (spelled Calcutta before 1 January 2001) is the capital city of the Indian state of West Bengal. It is the second largest city in India after Mumbai. It is on the east bank of the River Hooghly. When it is called Calcutta, it includes the suburbs. This makes it the third largest city of India. This also makes it the world's 8th largest metropolitan area as defined by the United Nations. Kolkata served as the capital of India during the British Raj until 1911. Kolkata was once the center of industry and education. However, it has witnessed political violence and economic problems since 1954. Since 2000, Kolkata has grown due to economic growth. Like other metropolitan cities in India, Kolkata struggles with poverty, pollution and traffic congestion.\"),\n",
              " Document(page_content='Chennai (formerly known as Madras) is the capital city of the Indian state of Tamil Nadu. It has a population of about 7 million people. Almost 10% of all of the people in the state live in Chennai. The city is the fourth largest city of India. It was founded in 1661 by the British East India Company. The city is on the Coromandel Coast of the Bay of Bengal.'),\n",
              " Document(page_content='Gandhinagar is the capital city of Gujarat state in India. It is 23\\xa0km from the city of Ahmedabad and 464\\xa0km from Mumbai. In the year 1960, the Bombay state of India was divided into two states - Maharashtra and Gujarat. Bombay (now called Mumbai) became the capital city of Maharashtra. For Gujarat, new capital was needed. Gandhinagar was then made the capital of Gujarat.')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build a QA RAG Chain"
      ],
      "metadata": {
        "id": "Bfn4Z4Em55bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub"
      ],
      "metadata": {
        "id": "vHAf9pJhjiMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "prompt"
      ],
      "metadata": {
        "id": "tNKFORDLji7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f849b44a-3b3e-4b4b-8b3d-eec2c678ba86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = \"\"\"You are an assistant for question-answering tasks.\n",
        "            Use the following pieces of retrieved context to answer the question.\n",
        "            If you don't know the answer, just say that you don't know.\n",
        "            Keep the answer upto 5 lines unless the user asks for more information\n",
        "\n",
        "            Question:\n",
        "            {question}\n",
        "\n",
        "            Context:\n",
        "            {context}\n",
        "\n",
        "            Answer:\n",
        "         \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt)"
      ],
      "metadata": {
        "id": "8Pu5U9HNkl-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New LangChain Syntax for RAG Chain - Using LCEL"
      ],
      "metadata": {
        "id": "Ng4cKPYfmRyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "qa_rag_chain = (\n",
        "    {\n",
        "        \"context\": (similarity_retriever\n",
        "                      |\n",
        "                    format_docs),\n",
        "        \"question\": RunnablePassthrough()\n",
        "    }\n",
        "      |\n",
        "    prompt_template\n",
        "      |\n",
        "    chatgpt\n",
        ")"
      ],
      "metadata": {
        "id": "18p2bJahmLX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the capital of India?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "print(result.content)"
      ],
      "metadata": {
        "id": "njFlSt9Smznk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c825470-756a-4fa0-eaee-862411bc720d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of India is New Delhi, which is a union territory of the megacity of Delhi. It has a population of about 9.4 million people and is located in the North Indian zone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Tell me about the financial capital of India\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "print(result.content)"
      ],
      "metadata": {
        "id": "-OfsGdmhnn6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fffd128-b0ad-4762-f933-0f18eab4195c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The financial capital of India is Mumbai, which is home to the National Stock Exchange of India Limited (NSE) and the headquarters of the State Bank of India (SBI). Mumbai is the biggest stock exchange in India and the largest bank in the country. The city plays a significant role in the economy of India, being the financial hub of the country.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who was the winner of the champions league in 2020?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "print(result.content)"
      ],
      "metadata": {
        "id": "PS5f9QKVn935",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76777427-3b4d-4b63-bf2f-39236c5ac6c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the financial capital of India?\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0KunWF9Fnaj",
        "outputId": "4f3558af-1fa9-48f1-9ef4-e0e69f15dd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The financial capital of India is Mumbai.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Tell me more about it in detail\"\n",
        "result = qa_rag_chain.invoke(query)\n",
        "print(result.content)"
      ],
      "metadata": {
        "id": "VwnV1fvWPILC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a0a3188-500a-4732-9569-86790d25d6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py:342: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.2\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but without specific context or information provided, I don't have any details to share. If you can provide more details or a specific topic, I would be happy to help with more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVemECCPfYg0"
      },
      "source": [
        "# Conversational RAG System with LangChain\n",
        "\n",
        "In many Q&A applications, the ability to engage in back-and-forth conversations with users is crucial. This necessitates the application having a form of \"memory\" to recall past interactions and apply this context to current queries.\n",
        "\n",
        "This guide focuses on integrating historical messages into the application's logic. Additional details on managing chat history can be found [here](https://python.langchain.com/docs/expression_language/how_to/message_history/).\n",
        "\n",
        "### Building on the Q&A RAG System - to a Conversational Q&A RAG System\n",
        "\n",
        "We will enhance our Q&A RAG System, which utilizes the Wikipedia dataset, by implementing the following updates:\n",
        "\n",
        "- **Prompt Adjustment:** Our prompt will be modified to include historical messages as inputs, allowing the system to maintain context over the course of a conversation.\n",
        "\n",
        "- **Contextualizing Questions:** We will introduce a sub-chain mechanism to reformulate the latest user query by considering the chat history. This is crucial for understanding questions that refer back to previous messages. For example, a query like \"Can you elaborate on the second point?\" relies on the context provided by preceding interactions, which affects the system's ability to retrieve relevant information effectively.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contextualizing the Question\n",
        "\n",
        "To maintain a seamless flow in conversations, especially in a Q&A setting, it's essential to incorporate historical interactions. Here’s how we achieve this:\n",
        "\n",
        "### Defining a Sub-Chain for Historical Context\n",
        "\n",
        "1. **Sub-Chain Creation:** We'll define a sub-chain that uses both historical messages and the latest user query. This sub-chain reformulates the question if it refers to any past interactions, ensuring the system, especially the vector database understands the context to return the most relevant documents to this newly reworded question.\n",
        "\n",
        "2. **Using `MessagesPlaceholder`:** Our prompt construction involves a `MessagesPlaceholder` variable named `chat_history`. This setup allows us to input a list of messages using the `chat_history` key. The system integrates these messages, positioning them after its own responses and before the latest user question.\n",
        "\n",
        "3. **Helper Function Usage:** We employ the `create_history_aware_retriever` function available [here](https://api.python.langchain.com/en/latest/chains/langchain.chains.history_aware_retriever.create_history_aware_retriever.html). This function is crucial for handling instances where the chat history might be empty and orchestrates the sequence of operations: `prompt | llm | StrOutputParser() | retriever`.\n",
        "\n",
        "4. **Chain Construction:** The `create_history_aware_retriever` constructs a chain that processes inputs under the keys `input` and `chat_history`, ensuring the output schema aligns with that of a retriever.\n",
        "\n",
        "By implementing these steps, our system can effectively utilize historical context to better understand and respond to user queries, thereby enhancing the conversational experience.\n"
      ],
      "metadata": {
        "id": "H0sMxGqEojYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rephrase_prompt = hub.pull(\"langchain-ai/chat-langchain-rephrase\")\n",
        "rephrase_prompt"
      ],
      "metadata": {
        "id": "qBXdc-uz4WSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e966395-f1d7-4461-9da5-bf368a389cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['chat_history', 'input'], metadata={'lc_hub_owner': 'langchain-ai', 'lc_hub_repo': 'chat-langchain-rephrase', 'lc_hub_commit_hash': 'fb7ddb56be11b2ab10d176174dae36faa2a9a6ba13187c8b2b98315f6ca7d136'}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {input}\\nStandalone Question:')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rephrase_prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG_6njQiGvjd",
        "outputId": "91adfd1e-5a78-473d-cb03-fb49dd344b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
            "\n",
            "Chat History:\n",
            "{chat_history}\n",
            "Follow Up Input: {input}\n",
            "Standalone Question:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "rephrase_system_prompt = \"\"\"Given a chat history and the latest user question\n",
        "which might reference context in the chat history, formulate a standalone question\n",
        "which can be understood without the chat history. Do NOT answer the question,\n",
        "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
        "\n",
        "rephrase_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", rephrase_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    chatgpt, similarity_retriever, rephrase_prompt\n",
        ")\n",
        "\n",
        "history_aware_retriever"
      ],
      "metadata": {
        "id": "1Drh0P1d2s0m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef050bf9-8ef2-4522-e839-957b0d1f03b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
              "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7a81797a71c0>, search_type='similarity_score_threshold', search_kwargs={'k': 5, 'score_threshold': 0.2}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Given a chat history and the latest user question \\nwhich might reference context in the chat history, formulate a standalone question \\nwhich can be understood without the chat history. Do NOT answer the question, \\njust reformulate it if needed and otherwise return it as is.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7a8196385300>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7a81792b4fd0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
              "| StrOutputParser()\n",
              "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7a81797a71c0>, search_type='similarity_score_threshold', search_kwargs={'k': 5, 'score_threshold': 0.2})), config={'run_name': 'chat_retriever_chain'})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chain prepends a rephrasing of the input query to our retriever, so that the retrieval incorporates the context of the conversation."
      ],
      "metadata": {
        "id": "QN2SIBOs29Si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the QA RAG Chain with Chat History\n",
        "\n",
        "Now we're ready to construct our comprehensive QA RAG chain, which leverages historical context for more accurate and relevant responses.\n",
        "\n",
        "### Components of the QA RAG Chain\n",
        "\n",
        "1. **Creating Document Chains:**\n",
        "   - We use the `create_stuff_documents_chain` function, which is detailed [here](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html). This function is used to create a `question_answer_chain`, accepting inputs such as `context`, `chat_history`, and `input`. It efficiently combines the retrieved context with the conversation history and the current query to generate an informed answer.\n",
        "\n",
        "2. **Building the Final QA RAG Chain:**\n",
        "   - The entire QA RAG chain is assembled using the `create_retrieval_chain` function, available [here](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval.create_retrieval_chain.html). This chain integrates the `history_aware_retriever` with the `question_answer_chain`. It retains intermediate outputs like the retrieved context for added convenience during the query handling process.\n",
        "   - The `create_retrieval_chain` function accepts keys such as `input` and `chat_history` and includes `input`, `chat_history`, `context`, and `answer` in its outputs.\n",
        "\n",
        "By implementing these steps, the system not only contextualizes but also provides accurate answers by synthesizing information from both the current and historical interactions. This method enhances the conversational AI’s ability to understand and respond to user queries dynamically, making the interactions more engaging and relevant.\n"
      ],
      "metadata": {
        "id": "67lm91Yl5eJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks.\n",
        "                      Use the following pieces of retrieved context to answer the question.\n",
        "                      If you don't know the answer, just say that you don't know.\n",
        "                      Keep the answer upto 5 lines unless the user asks for more information\n",
        "\n",
        "                      Context:\n",
        "                      {context}\n",
        "                  \"\"\"\n",
        "\n",
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", qa_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(chatgpt, qa_prompt)\n",
        "\n",
        "qa_rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
        "qa_rag_chain"
      ],
      "metadata": {
        "id": "f8v6WgeG5KQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3bc6e7-c3b0-4f66-adc8-08a785f17ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunnableBinding(bound=RunnableAssign(mapper={\n",
              "  context: RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
              "           | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7a81797a71c0>, search_type='similarity_score_threshold', search_kwargs={'k': 5, 'score_threshold': 0.2}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Given a chat history and the latest user question \\nwhich might reference context in the chat history, formulate a standalone question \\nwhich can be understood without the chat history. Do NOT answer the question, \\njust reformulate it if needed and otherwise return it as is.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
              "           | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7a8196385300>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7a81792b4fd0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
              "           | StrOutputParser()\n",
              "           | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7a81797a71c0>, search_type='similarity_score_threshold', search_kwargs={'k': 5, 'score_threshold': 0.2})), config={'run_name': 'retrieve_documents'})\n",
              "})\n",
              "| RunnableAssign(mapper={\n",
              "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
              "              context: RunnableLambda(format_docs)\n",
              "            }), config={'run_name': 'format_inputs'})\n",
              "            | ChatPromptTemplate(input_variables=['chat_history', 'context', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"You are an assistant for question-answering tasks.\\n                      Use the following pieces of retrieved context to answer the question.\\n                      If you don't know the answer, just say that you don't know.\\n                      Keep the answer upto 5 lines unless the user asks for more information\\n\\n                      Context:\\n                      {context}\\n                  \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
              "            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7a8196385300>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7a81792b4fd0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
              "            | StrOutputParser(), config={'run_name': 'stuff_documents_chain'})\n",
              "  }), config={'run_name': 'retrieval_chain'})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "\n",
        "question = \"What is the capital of India?\"\n",
        "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
        "print(response['answer'])"
      ],
      "metadata": {
        "id": "mPguXvkG7b6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "231ab1c7-c8bf-4f79-e2be-e1c962a5432e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of India is New Delhi, which is a union territory of the megacity of Delhi. It has a population of about 9.4 million people.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in qa_rag_chain.stream({\"input\": question, \"chat_history\": chat_history}):\n",
        "  print(chunk)"
      ],
      "metadata": {
        "id": "3Osi23E2zEDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79196ea7-e07a-4956-9d3c-8ee6d4f14df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'What is the capital of India?', 'chat_history': []}\n",
            "{'context': [Document(page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'), Document(page_content='The Republic of India is divided into twenty-eight States,and eight union territories including the National Capital Territory.'), Document(page_content=\"Kolkata (spelled Calcutta before 1 January 2001) is the capital city of the Indian state of West Bengal. It is the second largest city in India after Mumbai. It is on the east bank of the River Hooghly. When it is called Calcutta, it includes the suburbs. This makes it the third largest city of India. This also makes it the world's 8th largest metropolitan area as defined by the United Nations. Kolkata served as the capital of India during the British Raj until 1911. Kolkata was once the center of industry and education. However, it has witnessed political violence and economic problems since 1954. Since 2000, Kolkata has grown due to economic growth. Like other metropolitan cities in India, Kolkata struggles with poverty, pollution and traffic congestion.\"), Document(page_content='Gandhinagar is the capital city of Gujarat state in India. It is 23\\xa0km from the city of Ahmedabad and 464\\xa0km from Mumbai. In the year 1960, the Bombay state of India was divided into two states - Maharashtra and Gujarat. Bombay (now called Mumbai) became the capital city of Maharashtra. For Gujarat, new capital was needed. Gandhinagar was then made the capital of Gujarat.'), Document(page_content='Chennai (formerly known as Madras) is the capital city of the Indian state of Tamil Nadu. It has a population of about 7 million people. Almost 10% of all of the people in the state live in Chennai. The city is the fourth largest city of India. It was founded in 1661 by the British East India Company. The city is on the Coromandel Coast of the Bay of Bengal.')]}\n",
            "{'answer': ''}\n",
            "{'answer': 'The'}\n",
            "{'answer': ' capital'}\n",
            "{'answer': ' of'}\n",
            "{'answer': ' India'}\n",
            "{'answer': ' is'}\n",
            "{'answer': ' New'}\n",
            "{'answer': ' Delhi'}\n",
            "{'answer': ','}\n",
            "{'answer': ' which'}\n",
            "{'answer': ' is'}\n",
            "{'answer': ' a'}\n",
            "{'answer': ' union'}\n",
            "{'answer': ' territory'}\n",
            "{'answer': ' of'}\n",
            "{'answer': ' the'}\n",
            "{'answer': ' meg'}\n",
            "{'answer': 'acity'}\n",
            "{'answer': ' of'}\n",
            "{'answer': ' Delhi'}\n",
            "{'answer': '.'}\n",
            "{'answer': ' It'}\n",
            "{'answer': ' has'}\n",
            "{'answer': ' a'}\n",
            "{'answer': ' population'}\n",
            "{'answer': ' of'}\n",
            "{'answer': ' about'}\n",
            "{'answer': ' '}\n",
            "{'answer': '9'}\n",
            "{'answer': '.'}\n",
            "{'answer': '4'}\n",
            "{'answer': ' million'}\n",
            "{'answer': ' people'}\n",
            "{'answer': '.'}\n",
            "{'answer': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZxkLV4bJkOt",
        "outputId": "71ebeab3-8ca4-4a63-b71b-a57ff440ca84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "chat_history.extend([HumanMessage(content=question),\n",
        "                     AIMessage(content=response[\"answer\"])])\n",
        "chat_history"
      ],
      "metadata": {
        "id": "v_fPkZ9P7rF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc0029e7-ac30-4109-ca5a-27db9612f7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is the capital of India?'),\n",
              " AIMessage(content='The capital of India is New Delhi, which is a union territory of the megacity of Delhi. It has a population of about 9.4 million people.')]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Tell me more about this city\"\n",
        "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
        "print(response['answer'])"
      ],
      "metadata": {
        "id": "nZRM06Y375LF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ef4d548-b04a-409c-bc1c-028befff4d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Delhi, the capital of India, has a very old history and is home to several monuments. It is an expensive city to live in and falls under the North Indian zone in traditional Indian geography. The city has an area of about 42.7 km.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history.extend([HumanMessage(content=question),\n",
        "                     AIMessage(content=response[\"answer\"])])\n",
        "chat_history"
      ],
      "metadata": {
        "id": "ozckE4Hr8yOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d4ad2f-a9d0-4bf9-ba11-1c08d4bb68f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is the capital of India?'),\n",
              " AIMessage(content='The capital of India is New Delhi, which is a union territory of the megacity of Delhi. It has a population of about 9.4 million people.'),\n",
              " HumanMessage(content='Tell me more about this city'),\n",
              " AIMessage(content='New Delhi, the capital of India, has a very old history and is home to several monuments. It is an expensive city to live in and falls under the North Indian zone in traditional Indian geography. The city has an area of about 42.7 km.')]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Can fish really fly?\"\n",
        "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
        "print(response['answer'])"
      ],
      "metadata": {
        "id": "xQqNj73E8zVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca6a573-bd5d-43a7-c1ef-1c77ad53b086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flying fish, such as those in the Exocoetidae family, are known for their ability to glide above the water's surface, not actually fly like birds. They have winglike fins that help them glide for considerable distances to escape predators or catch prey.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op5Lb-9uJ5aI",
        "outputId": "0324692e-6eae-47c0-aa21-b4dc639f6912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Can fish really fly?',\n",
              " 'chat_history': [HumanMessage(content='What is the capital of India?'),\n",
              "  AIMessage(content='The capital of India is New Delhi, which is a union territory of the megacity of Delhi. It has a population of about 9.4 million people.'),\n",
              "  HumanMessage(content='Tell me more about this city'),\n",
              "  AIMessage(content='New Delhi, the capital of India, has a very old history and is home to several monuments. It is an expensive city to live in and falls under the North Indian zone in traditional Indian geography. The city has an area of about 42.7 km.')],\n",
              " 'context': [Document(page_content='Flying fish are marine oceanic fishes of the family Exocoetidae. They are about 50 species, and they live worldwide in warm waters. They are noted for their ability to glide. They are all small, with a maximum length of about 45 cm (18 inches), and have winglike, rigid fins and an unevenly forked tail.'),\n",
              "  Document(page_content='Bluefish is a kind of fish which occurs in the Atlantic Ocean, the Mediterranean, the Black Sea, the Indian Ocean and the Pacific. It is a pelagic fish, which means that it lives near the surface of the ocean. They can grow to a size of and reach a weight of . In the wild, they live to be about nine years old.'),\n",
              "  Document(page_content='The Pike Place Fish Market is an open air fish market located in Seattle, Washington at the corner of Pike Street and Pike Place. It is known for their tradition of fishmongers throwing fish that customers have purchased, before they are wrapped. After nearing bankruptcy in 1986, the fish market owner and employees decided to become \"world famous\", changing their way of doing business by introducing their flying fish, games, and customer performances. Four years later, they were featured repeatedly in the national media and television shows. The store is now a popular tourist destination in Seattle, attracting up to 10,000 daily visitors, and is often billed as world-famous.'),\n",
              "  Document(page_content='Archerfish (or archer fish) are small fish. Some live in fresh water. Others live in salt water. They live from India to the Philippines, Australia, and Polynesia.'),\n",
              "  Document(page_content='The clown fish is a kind of fish. Clownfish habitat usually is a coral reefs. Clownfish live in the Indian Ocean and the Pacific Ocean, from north west Australia, the coast of South East Asia as far north as Japan. Often, they live in a symbiosis with other animals, for instance the sea anemone. They live in anemones which are like plants under the sea. Anemones eat fish by killing them with their tentacles which are poisonous. Scientists believe that clown fish are protected from the poison because they are coated in a type of mucus.')],\n",
              " 'answer': \"Flying fish, such as those in the Exocoetidae family, are known for their ability to glide above the water's surface, not actually fly like birds. They have winglike fins that help them glide for considerable distances to escape predators or catch prey.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history.extend([HumanMessage(content=question),\n",
        "                     AIMessage(content=response[\"answer\"])])"
      ],
      "metadata": {
        "id": "ra8o20RH88WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history"
      ],
      "metadata": {
        "id": "WNkuQx7DezF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7fb6472-9810-4824-e34a-447d16ec9f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is the capital of India?'),\n",
              " AIMessage(content='The capital of India is New Delhi, which is a union territory of the megacity of Delhi. It has a population of about 9.4 million people.'),\n",
              " HumanMessage(content='Tell me more about this city'),\n",
              " AIMessage(content='New Delhi, the capital of India, has a very old history and is home to several monuments. It is an expensive city to live in and falls under the North Indian zone in traditional Indian geography. The city has an area of about 42.7 km.'),\n",
              " HumanMessage(content='Can fish really fly?'),\n",
              " AIMessage(content=\"Flying fish, such as those in the Exocoetidae family, are known for their ability to glide above the water's surface, not actually fly like birds. They have winglike fins that help them glide for considerable distances to escape predators or catch prey.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history[-2:]"
      ],
      "metadata": {
        "id": "84jh_iP5bEn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2748d60-86e0-4f53-aed8-c96e242e78e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Can fish really fly?'),\n",
              " AIMessage(content=\"Flying fish, such as those in the Exocoetidae family, are known for their ability to glide above the water's surface, not actually fly like birds. They have winglike fins that help them glide for considerable distances to escape predators or catch prey.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the fastest animal?\"\n",
        "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
        "chat_history.extend([HumanMessage(content=question),\n",
        "                     AIMessage(content=response[\"answer\"])])\n",
        "print(response['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5bN1VjaKT8n",
        "outputId": "5821b51a-a7eb-4cc6-c56d-4acc46626c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cheetah is the fastest land animal, capable of running up to 112 kilometers per hour for short distances.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Tell me about its different species\"\n",
        "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
        "chat_history.extend([HumanMessage(content=question),\n",
        "                     AIMessage(content=response[\"answer\"])])\n",
        "print(response['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s3Ii71fKa9U",
        "outputId": "f16a387b-cf4b-4522-ab90-dd14bd52f482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cheetah has different subspecies, including the Asiatic cheetah (\"Acinonyx jubatus venaticus\") native to Asia, and the South African Cheetah (\"Acinonyx jubatus jubatus\") native to Southern Africa. The South African Cheetah is the most abundant subspecies, with an estimated population of more than 6,000 individuals in the wild.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Returning Sources in Q&A Applications\n",
        "\n",
        "An essential feature of Q&A applications is the transparency in showing the sources that contributed to the generated answers. This builds trust and allows users to further explore the original content.\n",
        "\n",
        "### Integration with LangChain’s `create_retrieval_chain`\n",
        "\n",
        "- **Source Propagation:** LangChain’s `create_retrieval_chain` function is designed to ensure that source documents retrieved during the question answering process are included in the final output. This is particularly useful for maintaining transparency and providing users with the ability to trace answers back to their origins.\n",
        "- **Key Implementation:** The retrieved source documents are propagated through to the output under the \"context\" key. This feature not only supports the credibility of the answers provided but also enhances user engagement by allowing users to verify and explore the sources themselves.\n",
        "\n",
        "By utilizing this built-in functionality, developers can easily implement a system where users are always informed about the origins of the information provided, thereby enhancing the overall reliability and user experience of the Q&A application.\n"
      ],
      "metadata": {
        "id": "6xX-XlFK9UFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []"
      ],
      "metadata": {
        "id": "XXnvQpoXKzCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"which is the fastest animal?\"\n",
        "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
        "print('Answer:', response['answer'])\n",
        "print('Sources:')\n",
        "for document in response['context']:\n",
        "    print(document)\n",
        "    print()"
      ],
      "metadata": {
        "id": "d4NVMH2H9Aad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e137d363-832c-4709-9734-5237c816b3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: The fastest land animal is the cheetah, which can run up to 112 kilometers per hour for a short time.\n",
            "Sources:\n",
            "page_content='A cheetah (\"Acinonyx jubatus\") is a medium large cat which lives in Africa. It is the fastest land animal and can run up to 112 kilometers per hour for a short time. Most cheetahs live in the savannas of Africa. There are a few in Asia. Cheetahs are active during the day, and hunt in the early morning or late evening.'\n",
            "\n",
            "page_content='The Zebra Turkeyfish (\"Dendrochirus zebra\") is a very venomous fish. It lives in the Indian and Pacific seas. The fish has 13 venomous spines along its back, used to look after itself. The fish is slow and quiet, but can be a danger. The fish rests in dark places such as under a rock or a piece of coral. They aren\\'t affected by each other\\'s venom. They are solitary fish that are not scared of anything, as they have no predators other than groupers.'\n",
            "\n",
            "page_content='The Bengal tiger (\"Panthera tigris tigris\") is a tiger subspecies native to the Indian subcontinent. It lives in Bhutan, Nepal, Bangladesh and northern India. It is the National animal of both India and Bangladesh.'\n",
            "\n",
            "page_content='The South African Cheetah (\"Acinonyx jubatus jubatus\"), also known as Namibian Cheetah, is the nominate subspecies of cheetah native to Southern Africa. It is the most abundant subspecies estimated at more than 6,000 individuals in the wild. Since 1990 and onwards, the population was estimated at approximately 2,500 individuals in Namibia, until 2015, the cheetah population has been increased to more than 3,500 in the country.'\n",
            "\n",
            "page_content='The Indian elephant (\"Elephas maximus indicus\") is one of three subspecies of the Asian elephant. It comes from mainland Asia. Since 1986, Elephants \"maximus\" has been listed as endangered by IUCN. The population has declined by at least 50% over the last 60–75 years. The species is also threatened by habitat loss, degradation and herds being split apart into smaller groups. In India it is recognized as the National animal of the country.'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history.extend([HumanMessage(content=question),\n",
        "                     AIMessage(content=response[\"answer\"])])"
      ],
      "metadata": {
        "id": "hBUt6ZL89soR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Tell me more, including different types of this animal and their details\"\n",
        "response = qa_rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
        "print('Answer:', response['answer'])\n",
        "print('Sources:')\n",
        "for document in response['context']:\n",
        "    print(document)\n",
        "    print()"
      ],
      "metadata": {
        "id": "WzDIkfMk9z86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "578964e5-0fa8-4cf4-b205-af9045be0ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: The cheetah (\"Acinonyx jubatus\") is a medium-large cat found in Africa, known for its speed. They are active during the day and hunt in the early morning or late evening. Another type of fast animal is the cougar (\"Puma concolor\"), which is part of the Felinae subfamily of Felidae. Cougars are also known for their agility and speed in hunting.\n",
            "Sources:\n",
            "page_content='A cheetah (\"Acinonyx jubatus\") is a medium large cat which lives in Africa. It is the fastest land animal and can run up to 112 kilometers per hour for a short time. Most cheetahs live in the savannas of Africa. There are a few in Asia. Cheetahs are active during the day, and hunt in the early morning or late evening.'\n",
            "\n",
            "page_content='Flying fish are marine oceanic fishes of the family Exocoetidae. They are about 50 species, and they live worldwide in warm waters. They are noted for their ability to glide. They are all small, with a maximum length of about 45 cm (18 inches), and have winglike, rigid fins and an unevenly forked tail.'\n",
            "\n",
            "page_content='The flying snake, or \"Chrysopelea\", is a mildly venomous snake found throughout India to the Indonesian archipelago. It can glide, in an arboreal habitat, going from tree to tree, most likely, much like the draco lizard. They\\'re better at \"flying\" than another species of animal similar to this - the flying squirrel.'\n",
            "\n",
            "page_content='The Indian Chameleon, \"Chamaeleo zeylanicus\" is a species of chameleon found in Sri Lanka, India and other parts of South Asia. Like other chameleons, this species has a long tongue, feet that are shaped into bifid claspers and a prehensile tail. Its two eyes can move in different directions at the same time. It also can change the colour of its skin. They move slowly with a bobbing or swaying movement and are usually arboreal. Strangely, although they can change color, they may not be able to see differences in colour. They are usually in shades of green or brown or with bands. They can change colour quickly. The main reason for colour change is for communication with other chameleons and for controlling body temperature. By changing to dark colours, their bodies absorb heat.'\n",
            "\n",
            "page_content='The Felinae is a subfamily of the Felidae. It includes small cats and a few medium-large cats, especially the cougar (\"Puma concolor\") and the cheetah (\"Acinonyx jubatus\").'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FKPVPX3m95dF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}